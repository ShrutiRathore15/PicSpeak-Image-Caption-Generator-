{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "from math import ceil\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the input and output directory\n",
    "INPUT_DIR = r'C:\\Users\\shrut\\Image Captioning\\archive'\n",
    "OUTPUT_DIR = r'C:\\Users\\shrut\\Image Captioning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  A child in a pink dress is climbing up a set o...  \n",
       "1              A girl going into a wooden building .  \n",
       "2   A little girl climbing into a wooden playhouse .  \n",
       "3  A little girl climbing the stairs to her playh...  \n",
       "4  A little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'archive\\captions.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40563, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image      27\n",
       "caption    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40515, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['caption'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  a child in a pink dress is climbing up a set o...  \n",
       "1              a girl going into a wooden building .  \n",
       "2   a little girl climbing into a wooden playhouse .  \n",
       "3  a little girl climbing the stairs to her playh...  \n",
       "4  a little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting text to lower case\n",
    "data['caption']=data['caption'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punchuations\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "data['caption']=data['caption'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing single letter words eg. 'a' \n",
    "def remove_s(text):\n",
    "    return re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "\n",
    "data['caption']=data['caption'].apply(lambda x: ' '.join(remove_s(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>child in  pink dress is climbing up  set of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>girl going into  wooden building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl climbing into  wooden playhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl climbing the stairs to her playhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl in  pink dress going into  wooden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0   child in  pink dress is climbing up  set of s...  \n",
       "1                   girl going into  wooden building  \n",
       "2        little girl climbing into  wooden playhouse  \n",
       "3   little girl climbing the stairs to her playhouse  \n",
       "4   little girl in  pink dress going into  wooden...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the words with no. in them\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\b\\w*\\d\\w*\\b', '', text)\n",
    "\n",
    "data['caption']=data['caption'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\shrut\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_spelling_mistakes\u001b[39m(text):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m english_words)\n\u001b[1;32m---> 12\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(filter_spelling_mistakes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Checking for spelling mistakes\n",
    "\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "\n",
    "english_words = set(words.words())\n",
    "\n",
    "def filter_spelling_mistakes(text):\n",
    "    return ' '.join(word for word in text.split() if word.lower() in english_words)\n",
    "\n",
    "data['caption']=data['caption'].apply(filter_spelling_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>child in pink dress is climbing up set of in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>girl going into wooden building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl climbing into wooden playhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl climbing the to her playhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>little girl in pink dress going into wooden cabin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  child in pink dress is climbing up set of in a...  \n",
       "1                    girl going into wooden building  \n",
       "2         little girl climbing into wooden playhouse  \n",
       "3          little girl climbing the to her playhouse  \n",
       "4  little girl in pink dress going into wooden cabin  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(text):\n",
    "    return 'startseq ' + ' '.join([word for word in text.split() if len(word) > 1]) + ' endseq'\n",
    "\n",
    "data['caption']=data['caption'].apply(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"captions__.txt\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'startseq girl going into wooden building endseq'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['caption'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading VGG Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, concatenate, Bidirectional, Dot, Activation, RepeatVector, Multiply, Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = {}\n",
    "\n",
    "img_dir = os.path.join(INPUT_DIR, 'Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shrut\\\\Image Captioning\\\\archive\\\\Images'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 997722733_0cb5439472.jpg: 100%|██████████| 8091/8091 [59:25<00:00,  2.27it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Iterate over the files in the directory\n",
    "with tqdm(os.listdir(img_dir)) as pbar:\n",
    "    for img_name in pbar:\n",
    "        # Updating tqdm with the current filename\n",
    "        pbar.set_description(f'Processing {img_name}')\n",
    "        \n",
    "        # Loading the image from file\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        \n",
    "        # Converting image pixels to a numpy array\n",
    "        image = img_to_array(image)\n",
    "        \n",
    "        # Reshapeing the data for the model\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        \n",
    "        image = preprocess_input(image)\n",
    "        # Extracting features using the pre-trained VGG16 model\n",
    "        image_feature = model.predict(image, verbose=0)\n",
    "        \n",
    "        image_id = img_name.split('.')[0]\n",
    "        \n",
    "        image_features[image_id] = image_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the image features in pickle\n",
    "pickle.dump(image_features, open(os.path.join(OUTPUT_DIR, 'img_features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = os.path.join(OUTPUT_DIR, 'img_features.pkl')\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading caption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\shrut\\Image Captioning'\n",
    "\n",
    "with open(os.path.join(path, 'captions__.txt'), 'r') as file:\n",
    "    next(file)\n",
    "    captions_doc = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Caption Maping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40446/40446 [00:00<00:00, 491113.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of captions: 40445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_to_captions_mapping = defaultdict(list)\n",
    "\n",
    "# Processing lines from captions_doc\n",
    "for line in tqdm(captions_doc.split('\\n')):\n",
    "    # Spliting the line by comma(,)\n",
    "    tokens = line.split(',')\n",
    "    if len(tokens) < 2:\n",
    "        continue\n",
    "    image_id, *captions = tokens\n",
    "    # Removing extension from image ID\n",
    "    image_id = image_id.split('.')[0]\n",
    "    # Converting captions list to string\n",
    "    caption = \" \".join(captions)\n",
    "    # Storing the caption using defaultdict\n",
    "    image_to_captions_mapping[image_id].append(caption)\n",
    "\n",
    "\n",
    "total_captions = sum(len(captions) for captions in image_to_captions_mapping.values())\n",
    "print(\"Total number of captions:\", total_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq black dog green toy in his mouth as he through the grass endseq',\n",
       " 'startseq black dog carrying something through the grass endseq',\n",
       " 'startseq black dog blue toy in its mouth endseq',\n",
       " 'startseq dog in grass with blue item in his mouth endseq',\n",
       " 'startseq wet black dog is carrying green toy through the grass endseq']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_to_captions_mapping['1026685415_0431cbf574']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq',\n",
       " 'startseq black dog and spotted dog are fighting endseq',\n",
       " 'startseq black dog and tricolored dog with each other on the road endseq',\n",
       " 'startseq black dog and white dog with brown are staring at each other in the street endseq',\n",
       " 'startseq two dogs of different looking at each other on the road endseq',\n",
       " 'startseq two dogs on pavement moving toward each other endseq']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a List of All Captions\n",
    "all_captions = [caption for captions in image_to_captions_mapping.values() for caption in captions]\n",
    "all_captions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 4862\n",
      "Maximum Caption Length: 29\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum caption length\n",
    "max_caption_length = max(len(tokenizer.texts_to_sequences([caption])[0]) for caption in all_captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Maximum Caption Length:\", max_caption_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a List of Image IDs\n",
    "image_ids = list(image_to_captions_mapping.keys())\n",
    "# Splitting into Training and Test Sets\n",
    "split = int(len(image_ids) * 0.90)\n",
    "train = image_ids[:split]\n",
    "test = image_ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator function\n",
    "def data_generator(data_keys, image_to_captions_mapping, features, tokenizer, max_caption_length, vocab_size, batch_size):\n",
    "    # Lists to store batch data\n",
    "    X1_batch, X2_batch, y_batch = [], [], []\n",
    "    # Counter for the current batch size\n",
    "    batch_count = 0\n",
    "\n",
    "    while True:\n",
    "        # Loop through each image in the current batch\n",
    "        for image_id in data_keys: \n",
    "            # Get the captions associated with the current image\n",
    "            captions = image_to_captions_mapping[image_id]\n",
    "\n",
    "            # Loop through each caption for the current image\n",
    "            for caption in captions:\n",
    "                # Convert the caption to a sequence of token IDs\n",
    "                caption_seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "\n",
    "                # Loop through the tokens in the caption sequence\n",
    "                for i in range(1, len(caption_seq)):\n",
    "                    # Split the sequence into input and output pairs\n",
    "                    in_seq, out_seq = caption_seq[:i], caption_seq[i]\n",
    "\n",
    "                    # Pad the input sequence to the specified maximum caption length\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_caption_length)[0]\n",
    "\n",
    "                    # Convert the output sequence to one-hot encoded format\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                    # Append data to batch lists\n",
    "                    X1_batch.append(features[image_id][0])  # Image features\n",
    "                    X2_batch.append(in_seq)  # Input sequence\n",
    "                    y_batch.append(out_seq)  # Output sequence\n",
    "\n",
    "                    # Increase the batch counter\n",
    "                    batch_count += 1\n",
    "\n",
    "                    # If the batch is complete, yield the batch and reset lists and counter\n",
    "                    if batch_count == batch_size:\n",
    "                        X1_batch, X2_batch, y_batch = np.array(X1_batch), np.array(X2_batch), np.array(y_batch)\n",
    "                        yield [X1_batch, X2_batch], y_batch\n",
    "                        X1_batch, X2_batch, y_batch = [], [], []\n",
    "                        batch_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 29, 256)      1244672     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 29, 256)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 29, 256)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 29, 512)      1050624     ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 29, 512)     1050624     ['dropout_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 29, 29)       0           ['bidirectional[0][0]',          \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 29, 29)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 29, 512)      0           ['activation[0][0]',             \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 512)         0           ['lambda[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 768)          0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          196864      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4862)         1249534     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,841,150\n",
      "Trainable params: 5,841,150\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "inputs1 = Input(shape=(4096,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "fe2_projected = RepeatVector(max_caption_length)(fe2)\n",
    "fe2_projected = Bidirectional(LSTM(256, return_sequences=True))(fe2_projected)\n",
    "\n",
    "# Sequence feature layers\n",
    "inputs2 = Input(shape=(max_caption_length,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = Bidirectional(LSTM(256, return_sequences=True))(se2)\n",
    "\n",
    "# Apply attention mechanism using Dot product\n",
    "attention = Dot(axes=[2, 2])([fe2_projected, se3])  # Calculate attention scores\n",
    "\n",
    "# Softmax attention scores\n",
    "attention_scores = Activation('softmax')(attention)\n",
    "\n",
    "# Apply attention scores to sequence embeddings\n",
    "attention_context = Lambda(lambda x: tf.einsum('ijk,ijl->ikl', x[0], x[1]))([attention_scores, se3])\n",
    "\n",
    "# Sum the attended sequence embeddings along the time axis\n",
    "context_vector = tf.reduce_sum(attention_context, axis=1)\n",
    "\n",
    "# Decoder model\n",
    "decoder_input = concatenate([context_vector, fe2], axis=-1)\n",
    "decoder1 = Dense(256, activation='relu')(decoder_input)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder1)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Visualize the model\n",
    "#plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "228/228 [==============================] - 141s 581ms/step - loss: 5.8957 - val_loss: 5.5019\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 138s 606ms/step - loss: 4.8545 - val_loss: 5.6050\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 137s 601ms/step - loss: 4.4913 - val_loss: 5.6553\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 143s 628ms/step - loss: 4.1049 - val_loss: 5.7720\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 139s 609ms/step - loss: 3.8436 - val_loss: 5.7017\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epochs, batch size\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Calculate the steps_per_epoch based on the number of batches in one epoch\n",
    "steps_per_epoch = ceil(len(train) / batch_size)\n",
    "validation_steps = ceil(len(test) / batch_size)  # Calculate the steps for validation data\n",
    "\n",
    "# model.compile(optimizer, loss)\n",
    "# Loop through the epochs for training\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    # Set up data generators\n",
    "    train_generator = data_generator(train, image_to_captions_mapping, loaded_features, tokenizer, max_caption_length, vocab_size, batch_size)\n",
    "    test_generator = data_generator(test, image_to_captions_mapping, loaded_features, tokenizer, max_caption_length, vocab_size, batch_size)\n",
    "    \n",
    "    model.fit(train_generator, epochs=1, steps_per_epoch=steps_per_epoch, validation_data=test_generator, validation_steps=validation_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(OUTPUT_DIR+'/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captions Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_index(index, tokenizer):\n",
    "    return next((word for word, idx in tokenizer.word_index.items() if idx == index), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(model, image_features, tokenizer, max_caption_length):\n",
    "    # Initialize the caption sequence\n",
    "    caption = 'startseq'\n",
    "    \n",
    "    # Generate the caption\n",
    "    for _ in range(max_caption_length):\n",
    "        # Convert the current caption to a sequence of token indices\n",
    "        sequence = tokenizer.texts_to_sequences([caption])[0]\n",
    "        # Pad the sequence to match the maximum caption length\n",
    "        sequence = pad_sequences([sequence], maxlen=max_caption_length)\n",
    "        # Predict the next word's probability distribution\n",
    "        yhat = model.predict([image_features, sequence], verbose=0)\n",
    "        # Get the index with the highest probability\n",
    "        predicted_index = np.argmax(yhat)\n",
    "        # Convert the index to a word\n",
    "        predicted_word = get_word_from_index(predicted_index, tokenizer)\n",
    "        \n",
    "        # Append the predicted word to the caption\n",
    "        caption += \" \" + predicted_word\n",
    "        \n",
    "        # Stop if the word is None or if the end sequence tag is encountered\n",
    "        if predicted_word is None or predicted_word == 'endseq':\n",
    "            break\n",
    "    \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 30.7/139.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 81.9/139.4 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 133.1/139.4 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- 139.4/139.4 kB 922.6 kB/s eta 0:00:00\n",
      "Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.0 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 133.1/215.0 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 215.0/215.0 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.3 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.3 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, comm, ipywidgets\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.2\n",
      "    Uninstalling comm-0.1.2:\n",
      "      Successfully uninstalled comm-0.1.2\n",
      "Successfully installed comm-0.2.1 ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: notebook in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (7.0.6)\n",
      "Collecting notebook\n",
      "  Downloading notebook-7.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from notebook) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from notebook) (2.25.1)\n",
      "Collecting jupyterlab<4.2,>=4.1.1 (from notebook)\n",
      "  Downloading jupyterlab-4.1.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from notebook) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from notebook) (6.3.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (21.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (3.1.2)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.5.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.9.2)\n",
      "Requirement already satisfied: overrides in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (23.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.14.1)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (2.0.10)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.17.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.7.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.58.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (2.0.4)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab<4.2,>=4.1.1->notebook)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (6.8.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (6.1.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (2.2.0)\n",
      "Requirement already satisfied: tomli in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (4.19.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook) (2023.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyterlab<4.2,>=4.1.1->notebook) (3.16.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook) (305.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook) (1.26.16)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (8.12.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (1.5.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from websocket-client->jupyter-server<3,>=2.4.0->notebook) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (3.0.43)\n",
      "Requirement already satisfied: stack-data in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.4.6)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.2.5)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: executing in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab<4.2,>=4.1.1->notebook) (0.2.2)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook)\n",
      "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading notebook-7.1.1-py3-none-any.whl (5.0 MB)\n",
      "   ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.0 MB 5.3 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.2/5.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/5.0 MB 2.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.4/5.0 MB 2.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.9/5.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.2/5.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.5/5.0 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.8/5.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.1/5.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.4/5.0 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.6/5.0 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.7/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.0/5.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.1/5.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.2/5.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.4/5.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.7/5.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.0/5.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.4/5.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.7/5.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.9/5.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.0/5.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading jupyterlab-4.1.4-py3-none-any.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.4 MB 5.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/11.4 MB 5.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/11.4 MB 6.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/11.4 MB 6.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/11.4 MB 6.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/11.4 MB 6.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.4 MB 5.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.4 MB 5.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.5/11.4 MB 6.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/11.4 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/11.4 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/11.4 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.4 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.4 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.4 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.8/11.4 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.1/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.2/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.5/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.5/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.8/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.3/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.4 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.4 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.3/11.4 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.6/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.4 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.9/11.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.2/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.8/77.8 kB ? eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.4/66.4 kB ? eta 0:00:00\n",
      "Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
      "Installing collected packages: webcolors, uri-template, types-python-dateutil, jsonpointer, h11, fqdn, httpcore, arrow, isoduration, httpx, jupyterlab, notebook\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 4.0.11\n",
      "    Uninstalling jupyterlab-4.0.11:\n",
      "      Successfully uninstalled jupyterlab-4.0.11\n",
      "  Attempting uninstall: notebook\n",
      "    Found existing installation: notebook 7.0.6\n",
      "    Uninstalling notebook-7.0.6:\n",
      "      Successfully uninstalled notebook-7.0.6\n",
      "Successfully installed arrow-1.3.0 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 isoduration-20.11.0 jsonpointer-2.4 jupyterlab-4.1.4 notebook-7.1.1 types-python-dateutil-2.8.19.20240106 uri-template-1.3.0 webcolors-1.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: backcall in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\shrut\\anaconda3\\envs\\imagecaptioning\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store actual and predicted captions\n",
    "actual_captions_list = []\n",
    "predicted_captions_list = []\n",
    "\n",
    "# Loop through the test data\n",
    "for key in tqdm(test):\n",
    "    # Get actual captions for the current image\n",
    "    actual_captions = image_to_captions_mapping[key]\n",
    "    # Predict the caption for the image using the model\n",
    "    predicted_caption = predict_caption(model, loaded_features[key], tokenizer, max_caption_length)\n",
    "    \n",
    "    # Split actual captions into words\n",
    "    actual_captions_words = [caption.split() for caption in actual_captions]\n",
    "    # Split predicted caption into words\n",
    "    predicted_caption_words = predicted_caption.split()\n",
    "    \n",
    "    # Append to the lists\n",
    "    actual_captions_list.append(actual_captions_words)\n",
    "    predicted_captions_list.append(predicted_caption_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.033663\n",
      "BLEU-2: 0.002394\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate BLEU score\n",
    "print(\"BLEU-1: %f\" % corpus_bleu(actual_captions_list, predicted_captions_list, weights=(1.0, 0, 0, 0)))\n",
    "print(\"BLEU-2: %f\" % corpus_bleu(actual_captions_list, predicted_captions_list, weights=(0.5, 0.5, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating caption\n",
    "def generate_caption(image_name):\n",
    "    # load the image\n",
    "    image_id = image_name.split('.')[0]\n",
    "    img_path = os.path.join(INPUT_DIR, \"Images\", image_name)\n",
    "    image = Image.open(img_path)\n",
    "    captions = image_to_captions_mapping[image_id]\n",
    "    print('---------------------Actual---------------------')\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "    # predict the caption\n",
    "    y_pred = predict_caption(model, loaded_features[image_id], tokenizer, max_caption_length)\n",
    "    print('--------------------Predicted--------------------')\n",
    "    print(y_pred)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
